"""
Generate a CSV of all addresses and apartments from data/durham_parcels.csv
(generated by export_parcels.py).

Note that addresses will show up multiple times if there are multiple voters
registered at the address. And for addresses with no registered voter, the
address will appear one time.
"""

from arcgis import utils
import pandas as pd
from tqdm import tqdm

lots = pd.read_csv('data/durham_parcels.csv')
lots_by_voter_address = lots.set_index(['clean_address_y'], drop=False)
lots_by_parcel_address = lots.set_index(['clean_address_x'], drop=False)
lots_by_number_address = lots.set_index(['clean_number_address'], drop=False)

searched = []
new_addresses = []

for i, row in tqdm(lots.iterrows(), total=lots.shape[0]):
    address = row['clean_full_street_y']
    if isinstance(address, float):
        address = row['clean_full_street_x']
    # Have we already searched this streed for addresses/apartments?
    if address in searched:
        continue
    searched.append(address)
    # Search for all addresses/apartments on the street to minimize HTTP calls:
    apartments = utils.find_unique_apartments(address)
    if len(apartments) == 0:
        continue
    # TODO if apartments exist for the address, remove the non-apartment
    # rows.
    if len(apartments) > 1:
        pass
    for a in apartments:
        # Don't add the address if it already exists in our dataset:
        in_voter_reg = a['clean_address'] in lots_by_voter_address.index
        if in_voter_reg:
            continue
        in_lots = a['clean_address'] in lots_by_parcel_address.index
        if in_lots:
            continue

        # This parcel id is often not correct b/c we do a bulk HTTP request
        # on the first parcel on a block. We need to add clean_number_address,
        # and add it as an index so that we can search for the matching street
        # and address number - if there is a match, use that. Otherwise nothing.
        number_address = a['clean_street_number'] + ' ' + a['clean_street_name'] + ' ' + a['clean_street_type']
        if len(a['clean_street_directional']) > 0:
            number_address = a['clean_street_number'] + ' ' + a['clean_street_directional'] + ' ' + a['clean_street_name'] + ' ' + a['clean_street_type']
        parcel_id = 0
        lat = 0
        lon = 0
        clean_number_address = ''
        if number_address in lots_by_number_address.index:
            match = lots_by_number_address.loc[[number_address]]
            parcel_id = match.iloc[0].PARCEL_ID
            lat = match.iloc[0].lat
            lon = match.iloc[0].long
            clean_number_address = match.iloc[0].clean_number_address

        # Found a new address that doesn't exist in our dataset, with no known
        # voter associated with it:
        new_addresses.append({
            'PARCEL_ID': parcel_id,
            'clean_number_address': clean_number_address,
            'clean_full_street_x': '',
            'clean_full_street_y': '',
            'clean_address_x': '',
            'clean_address_y': a['clean_address'],
            'lat': lat,
            'long': lon,
            'avg_age': 0,
            'percent_active_voters': 0,
            'num_voters': 0,
            'percent_democrat': 0
        })

if len(new_addresses) > 0:
    lots = lots.append(new_addresses, ignore_index=True)
    # print('{}: {} new addresses'.format(address, len(new_addresses)))

lots.PARCEL_ID = lots.PARCEL_ID.fillna(0).astype(int)
lots = lots.fillna('')
no_lot_address = lots['clean_address_x'].str.contains(r'^$').fillna(False)
lots['address'] = '' + lots['clean_address_x']
lots.loc[no_lot_address, 'address'] = '' + lots.loc[no_lot_address, 'clean_address_y']

# Manually assign some parcel ids for locations where we know that the city
# address doesn't match a parcel (parcel data shows one address when it is
# actually, another):
#
# Precinct 21:
big_apartments = lots.address.str.startswith('3523 N ROXBORO')
lots.loc[big_apartments, 'PARCEL_ID'] = 128505

lots.rename(columns={'clean_number_address': 'parcel_address', 'clean_address_y': 'clean_address'}, inplace=True)
lots[[
    'PARCEL_ID', 'LANDUSE_DE', 'parcel_address', 'clean_address',
    'lat', 'long', 'avg_age', 'percent_active_voters', 'num_voters', 'percent_democrat'
]].to_csv('data/durham_addresses.csv.gz', compression='gzip', index=False)
